## Codebase Patterns
- Project uses FastAPI with Python 3.12, async SQLAlchemy, Redis
- All config via pydantic-settings with env vars
- Use structlog for JSON logging
- Docker-compose has postgres (PostGIS), Redis, API services
- All API responses must include data_quality object
- REST endpoints under /v1/ prefix
- File naming: snake_case.py for Python
- Type annotations required on all functions
- Google-style docstrings
- Runtime is Python 3.10 (not 3.12) — use `from __future__ import annotations` for newer type syntax
- Redis class is not generic at runtime in this redis version — use `# type: ignore[type-arg]` or `from __future__ import annotations`
- `postal` library requires libpostal C library — commented out in requirements.txt
- Middleware/auth/rate-limit must handle Redis unavailability gracefully (try/except) for tests and degraded mode
- Lifecycle startup should warn (not crash) when DB/Redis unavailable
- ruff config ignores B008 (Depends in defaults) and PLR2004 (magic numbers in tests)
- pyproject.toml in api/ configures ruff, mypy, and pytest
- Run quality checks from api/ directory: `python3 -m ruff check app/ tests/`, `python3 -m mypy app/`, `python3 -m pytest tests/ -v`
- Use `from __future__ import annotations` + `TYPE_CHECKING` block for forward references in models
- All model tables live in `parcel` schema — set via `__table_args__`
- Composite indexes go in `__table_args__` tuple, simple column indexes use `index=True` on `mapped_column`
- Alembic `env.py` must `import app.models` to register models with `Base.metadata`
- Exclude `alembic/` from both ruff and mypy (auto-generated migration style)
- geoalchemy2/pgvector mypy ignores are handled in pyproject.toml `[[tool.mypy.overrides]]`

---

## 2026-02-18 - S1-S14 (API Foundation)
- Implemented all 14 code stories for P10-01 API Foundation
- Files created:
  - api/app/config.py (S2: Pydantic Settings)
  - api/app/logging_config.py (S9: structlog setup)
  - api/app/database/__init__.py, connection.py, redis.py (S3, S4: DB + Redis)
  - api/app/lifecycle.py (S12: startup/shutdown)
  - api/app/middleware/__init__.py, error_handler.py, authentication.py, rate_limit.py (S6-S8, S13)
  - api/app/routes/__init__.py, health.py, properties.py, analytics.py, auth.py (S5, S14)
  - api/app/main.py (S1, S10: FastAPI app + CORS)
  - api/alembic/ (S11: migration framework)
  - api/pyproject.toml (tool config)
  - api/tests/conftest.py, test_health.py (4 tests)
- Files modified:
  - api/requirements.txt (commented out postal)
- **Learnings for future iterations:**
  - Python runtime is 3.10, not 3.12 — use `from __future__ import annotations` for union syntax
  - Redis[Any] type annotation crashes at runtime — need `from __future__ import annotations` or `# type: ignore`
  - postal lib needs libpostal C headers — not available in this env
  - Auth/rate-limit middleware must gracefully handle Redis being unavailable
  - Lifecycle startup should warn, not crash, when services are down
  - BaseHTTPMiddleware dispatch must accept `RequestResponseEndpoint` type for call_next
---

## 2026-02-18 - S15 (Docker Build Verification)
- Docker image `parceldata-api` builds successfully from api/Dockerfile
- PostgreSQL port 5432 may conflict with host postgres — use different port mapping if needed
- docker-compose.yml `version` attribute is deprecated (warning only)
- **Learnings for future iterations:**
  - Docker build works with Python 3.12-slim base image
  - Port conflicts are environment-specific; the build itself is valid
  - Add .dockerignore to api/ to speed up builds (exclude __pycache__, .git, etc.)
---

## 2026-02-18 - S1-S15 (P10-02 Data Models)
- Implemented all 15 stories for P10-02 Data Models
- Files created:
  - api/app/models/base.py (S1: TimestampMixin, DataQualityMixin, ProvenanceMixin)
  - api/app/models/property.py (S2: core Property with PostGIS + pgvector)
  - api/app/models/address.py (S3: normalized addresses)
  - api/app/models/building.py (S4: building structures)
  - api/app/models/valuation.py (S5: assessed + estimated values)
  - api/app/models/ownership.py (S6: owner info)
  - api/app/models/zoning.py (S7: zoning restrictions, ARRAY + JSONB columns)
  - api/app/models/listing.py (S8: MLS listings)
  - api/app/models/transaction.py (S9: deed transfers)
  - api/app/models/permit.py (S10: building permits)
  - api/app/models/environmental.py (S11: hazards and risk)
  - api/app/models/school.py (S12: school assignments)
  - api/app/models/tax.py (S13: property taxes)
  - api/app/models/hoa.py (S13: HOA data)
  - api/app/models/__init__.py (S14: package exports)
  - api/alembic/versions/001_initial_schema.py (S15: migration)
  - api/tests/test_models_base.py (4 tests)
  - api/tests/test_models.py (60 tests)
  - api/tests/test_migration.py (5 tests)
- Files modified:
  - api/alembic/env.py (import all models for autogenerate)
  - api/pyproject.toml (exclude alembic/ from ruff)
- **Learnings for future iterations:**
  - Forward references in SQLAlchemy models: use `TYPE_CHECKING` block for imports + string names in `relationship()`
  - geoalchemy2 Geometry and pgvector Vector columns: use `Mapped[object | None]` type hint (not Mapped[Geometry])
  - str(ForeignKey.column) returns table.column without schema prefix — don't test for schema prefix
  - Migration files split into helper functions to avoid PLR0915 (>50 statements)
  - `alembic.versions.xxx` is not directly importable as a Python module — use `importlib.util.spec_from_file_location`
  - All 13 models: Property, Address, Building, Valuation, Ownership, Zoning, Listing, Transaction, Permit, Environmental, School, Tax, HOA
---

## 2026-02-18 - S1-S15 (P10-03 Core API)
- Implemented all 15 stories for P10-03 Core API
- Files created:
  - api/app/schemas/__init__.py, property.py (S1: 16 Pydantic response schemas)
  - api/app/schemas/search.py (S5: SearchRequest/SearchResponse, BatchLookup)
  - api/app/schemas/analytics.py (S7: ComparableProperty, ComparablesResponse, MarketTrendsResponse)
  - api/app/services/property_service.py (S2: lookup by ID/address/coords, model-to-schema conversion)
  - api/app/services/search_service.py (S4: SearchFilters, dynamic query building with conditional joins)
  - api/app/services/comparables_service.py (S6: comparable sales with similarity scoring)
  - api/app/graphql/__init__.py, schema.py (S10: Strawberry GraphQL types + Query resolver)
  - api/app/utils/__init__.py, pagination.py (S13: CursorPage, encode/decode cursor)
  - api/tests/test_schemas.py (24 tests), test_property_service.py (9 tests)
  - api/tests/test_comparables_service.py (6 tests), test_pagination.py (7 tests)
  - api/tests/test_properties.py (14 integration tests including data_quality checks)
- Files modified:
  - api/app/routes/properties.py (S3, S5, S8, S9: lookup, search, batch, field selection)
  - api/app/routes/analytics.py (S7: comparables and market trends endpoints)
  - api/app/main.py (S11, S12, S15: GraphQL mount, OpenAPI docs, exception handlers with data_quality)
  - api/app/middleware/error_handler.py (S15: data_quality in error responses)
  - api/app/middleware/authentication.py (S15: data_quality in 401 responses)
  - api/app/middleware/rate_limit.py (S15: data_quality in 429 responses)
  - api/pyproject.toml (added PLR0912, PLR0915 to ruff ignores)
  - api/tests/test_health.py (updated assertions for route changes)
- Key patterns:
  - `ExecutableOption` from `sqlalchemy.sql.base` for typing selectinload lists
  - `ColumnElement[bool]` from sqlalchemy for typing dynamic WHERE conditions
  - Token-optimized response tiers: micro/standard/extended/full via `?detail=` param
  - Field selection via `?select=` always preserves data_quality
  - All error responses (401, 404, 422, 429, 500) include data_quality object
  - SearchResponse and BatchLookupResponse compute aggregate data_quality
  - Strawberry GraphQL resolves properties with DataQualityType
- 129 total tests passing
- **Learnings for future iterations:**
  - Middleware JSONResponse returns bypass FastAPI exception handlers — must add data_quality manually
  - Route order matters in FastAPI: /{property_id} must come after /search, /batch, /address/lookup, /coordinates/lookup
  - Integration tests without DB: accept both expected status and 500 (connection refused)
  - `SearchResponse.data_quality` is aggregate of individual result scores
---

